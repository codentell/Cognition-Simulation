{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from supabase import create_client, Client\n",
    "from pathlib import Path\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get json from Supabase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get keys and url for supabase\n",
    "url: str = os.environ.get(\"VITE_SUPABASE_URL\")\n",
    "key: str = os.environ.get(\"VITE_SUPABASE_KEY\")\n",
    "supabase: Client = create_client(url, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = supabase.table(\"users\").select(\"*\").execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort responses based on last push to database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'cbcbc11d-a455-443d-8fc2-f4645be44460',\n",
       "  'user': {'seed': 'Over the past several years, advanced footwear has become an essential tool for runners to improve their fitness and performance. However, they have continued facing challenges with heat building up inside running shoes that can lead to sweating and blisters. This will not only produce more discomfort, but also prevent them from increasing speed and endurance due to lingering pain. Therefore, future innovations need to overcome these issues with advanced footwear to improve the lives of runners across the globe.',\n",
       "   'steps': {'problem or task representation': 'present a task to be engaged in or a problem to be solved. Pose this yourself',\n",
       "    'preparation': 'build up or reactivate a store of information relevant to the problem or task, including a knowledge of response algorithms for working problems in the domain in question.',\n",
       "    'generation': 'generate response possibilities by searching through the available pathways and exploring features of the environment that are relevant to the task at hand.',\n",
       "    'validation': '\\ntest response possibility for correctness or appropriateness against factual knowledge and relevant criteria.',\n",
       "    'outcome': 'assess if the test has been passed perfectly—if there is complete attainment of the original goal—the process terminates. If there is complete failure—if no reasonable response possibility has been generated—the process will also terminate. If there is some progress toward the goal—if at least a reasonable response possibility has been generated or if there is some evidence of \"getting warmer\"—the process returns to the first stage, where the problem is once again posed.'},\n",
       "   'metric': 'highly critical judgement',\n",
       "   'iters': 10},\n",
       "  'timestamp': '2024-12-27T06:07:33.004676+00:00'},\n",
       " {'id': '23c4d008-bbcb-4914-866a-e8f1d93670a0',\n",
       "  'user': {'seed': '',\n",
       "   'steps': {'e': 'e'},\n",
       "   'metric': ['quality',\n",
       "    'fairness',\n",
       "    'uniqueness',\n",
       "    'importance',\n",
       "    'feasibility'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T05:34:40.087618+00:00'},\n",
       " {'id': 'd0476fa4-0816-4245-afdc-c9941abad8c5',\n",
       "  'user': {'seed': '1',\n",
       "   'steps': {'3': '3'},\n",
       "   'metric': ['feasibility', 'importance'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T06:56:06.114979+00:00'},\n",
       " {'id': 'e12dfc59-4963-44f6-96e7-69b1aeabf507',\n",
       "  'user': {'seed': '3',\n",
       "   'steps': {'3': '3'},\n",
       "   'metric': ['importance', 'quality'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T06:56:54.216898+00:00'},\n",
       " {'id': '0ae381ed-6e0c-454d-8f77-9d423b2eb4b6',\n",
       "  'user': {'seed': 'e',\n",
       "   'steps': {'e': 'e'},\n",
       "   'metric': ['importance'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T07:03:27.823639+00:00'},\n",
       " {'id': '7742cd15-9e44-447c-85bf-79afcf07a966',\n",
       "  'user': {'seed': 'e',\n",
       "   'steps': {'e': 'e'},\n",
       "   'metric': ['importance'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T07:03:51.031299+00:00'},\n",
       " {'id': '30487219-c060-451e-80df-1f5e14448998',\n",
       "  'user': {'seed': '',\n",
       "   'steps': {'e': 'e'},\n",
       "   'metric': ['importance'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T07:04:16.846731+00:00'},\n",
       " {'id': '380f81a1-82cc-4595-94ff-036939083e9a',\n",
       "  'user': {'seed': '3',\n",
       "   'steps': {'3': '3'},\n",
       "   'metric': ['uniqueness'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T07:05:13.180547+00:00'},\n",
       " {'id': 'e900e64b-2686-412d-8691-e34a9d1b9c7d',\n",
       "  'user': {'seed': '',\n",
       "   'steps': {'e': 'e'},\n",
       "   'metric': ['importance'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T07:06:09.185879+00:00'},\n",
       " {'id': '40079cae-bba4-4db1-bfd6-fd3c402cb57e',\n",
       "  'user': {'seed': 'e',\n",
       "   'steps': {'e': 'e'},\n",
       "   'metric': ['importance'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T07:07:18.928086+00:00'},\n",
       " {'id': '4a29678d-5ffc-4444-b1d5-7158eabc2457',\n",
       "  'user': {'seed': 'r',\n",
       "   'steps': {'r': 'r'},\n",
       "   'metric': ['importance'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T07:08:52.932711+00:00'},\n",
       " {'id': 'bb375903-4bb7-4ece-80c8-5fdd2ae1a235',\n",
       "  'user': {'seed': 'e',\n",
       "   'steps': {'e': 'e'},\n",
       "   'metric': ['importance'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T07:10:34.138996+00:00'},\n",
       " {'id': 'd06117f3-2037-4f6f-9549-ae94d630281a',\n",
       "  'user': {'seed': '3',\n",
       "   'steps': {'3': '3'},\n",
       "   'metric': ['importance'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T07:13:11.420801+00:00'},\n",
       " {'id': '63af0eed-4a51-4e17-aeba-65e9a22514a5',\n",
       "  'user': {'seed': '3',\n",
       "   'steps': {'3': '3'},\n",
       "   'metric': ['importance'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T07:13:44.859616+00:00'},\n",
       " {'id': 'a07b8f3c-bdff-49b3-9f67-a33560897d9b',\n",
       "  'user': {'seed': 'e',\n",
       "   'steps': {'e': 'e'},\n",
       "   'metric': ['importance'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T07:14:04.491768+00:00'},\n",
       " {'id': '5d7a3d8f-5898-4704-89a4-4408af0d1920',\n",
       "  'user': {'seed': '2',\n",
       "   'steps': {'2': '2'},\n",
       "   'metric': ['importance'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T07:15:04.898269+00:00'},\n",
       " {'id': '9875153b-a118-45a8-90d9-0ad5cfc809a4',\n",
       "  'user': {'seed': 'e',\n",
       "   'steps': {'e': 'e'},\n",
       "   'metric': ['importance'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T07:16:01.752464+00:00'},\n",
       " {'id': 'd6d427c3-7ebc-4d59-9fc7-85b9fd36ab01',\n",
       "  'user': {'seed': 'r',\n",
       "   'steps': {'r': 'r'},\n",
       "   'metric': ['uniqueness'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T07:16:33.907621+00:00'},\n",
       " {'id': 'e2dfac99-3bf0-40da-b0cd-4a7667ea424f',\n",
       "  'user': {'seed': '3',\n",
       "   'steps': {'3': '3'},\n",
       "   'metric': ['importance'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T07:20:46.826302+00:00'},\n",
       " {'id': '8193a228-fce5-42bf-8496-c9aaab125552',\n",
       "  'user': {'seed': 'e',\n",
       "   'steps': {'e': 'e'},\n",
       "   'metric': ['importance'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T07:34:21.489795+00:00'},\n",
       " {'id': '3b1d4e7d-b710-48f0-baba-8ae679b6d0e5',\n",
       "  'user': {'seed': '',\n",
       "   'steps': {'r': 'r'},\n",
       "   'metric': ['importance'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T07:35:04.574759+00:00'},\n",
       " {'id': 'ea890254-4027-48db-b400-eb39980dee4b',\n",
       "  'user': {'seed': '',\n",
       "   'steps': {'r': 'r'},\n",
       "   'metric': ['importance'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T07:35:27.00919+00:00'},\n",
       " {'id': '7fb81f2c-fe5f-4f62-a055-5cd92ba52efc',\n",
       "  'user': {'seed': '',\n",
       "   'steps': {'r': 'r'},\n",
       "   'metric': ['importance'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T07:35:56.591641+00:00'},\n",
       " {'id': '269c88fc-81f0-476b-8f1e-116a9345f15a',\n",
       "  'user': {'seed': 'rrr',\n",
       "   'steps': {'r': 'rrr'},\n",
       "   'metric': ['importance'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T07:37:22.296364+00:00'},\n",
       " {'id': '450eb639-7619-487c-a69c-146e7b1ef388',\n",
       "  'user': {'seed': 'e',\n",
       "   'steps': {'e': 'e'},\n",
       "   'metric': ['importance'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T07:39:04.614586+00:00'},\n",
       " {'id': 'd149aee6-3e55-42f5-9220-29a55902ad69',\n",
       "  'user': {'seed': 'how to bake cookies',\n",
       "   'steps': {'bake': 'describe how to bake'},\n",
       "   'metric': ['importance'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T07:42:07.821081+00:00'},\n",
       " {'id': 'f0f74022-2846-439f-a462-15d5a6a86d97',\n",
       "  'user': {'seed': 'how to bake cookies',\n",
       "   'steps': {'bake cookies': 'describe how to bake cookies'},\n",
       "   'metric': ['importance'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T07:43:52.307085+00:00'},\n",
       " {'id': 'a41f1731-7ec9-41cf-8d77-7821ee83f6b3',\n",
       "  'user': {'seed': 'how to bake cookies',\n",
       "   'steps': {'bake cookies': 'describe how to bake cookies'},\n",
       "   'metric': ['importance'],\n",
       "   'iters': 10,\n",
       "   'temperature': 0.5},\n",
       "  'timestamp': '2024-12-28T07:46:07.052568+00:00'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses = sorted(response.data, key=lambda x: x['timestamp'])\n",
    "responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up keys for Gemini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads key from .env, make sure key is named <GEMINI_KEY> in .env\n",
    "# load_dotenv()\n",
    "# load_dotenv(verbose=True)\n",
    "env_path = Path('.') / '.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "key = os.environ.get('GEMINI_KEY')\n",
    "genai.configure(api_key=key)\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash-exp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Gemini with simple prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI learns patterns from data to make predictions or decisions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = model.generate_content(\n",
    "    \"Explain how AI works, limit response to 1 sentence and a max of 100 characters\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seed', 'problem or task representation', 'preparation', 'generation', 'validation', 'outcome']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>problem or task representation</th>\n",
       "      <th>preparation</th>\n",
       "      <th>generation</th>\n",
       "      <th>validation</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Over the past several years, advanced footwear...</td>\n",
       "      <td>Over the past several years, advanced footwear...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                seed  \\\n",
       "0  Over the past several years, advanced footwear...   \n",
       "\n",
       "                      problem or task representation preparation generation  \\\n",
       "0  Over the past several years, advanced footwear...         NaN        NaN   \n",
       "\n",
       "  validation outcome  \n",
       "0        NaN     NaN  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = responses[0]['user']['seed']\n",
    "cols = list(responses[0]['user']['steps'].keys())\n",
    "cols.insert(0, \"seed\")\n",
    "print(cols)\n",
    "df = pd.DataFrame(columns=cols)\n",
    "for i in range(responses[0]['user']['iters']):\n",
    "    new_row = pd.DataFrame(\n",
    "        [{'seed': seed, 'problem or task representation': seed}])\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Gemini for steps using seed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- cache input tokens, to increase context window\n",
    "- creativity/variation slider on webpage\n",
    "- drop down for metric\n",
    "\n",
    "* https://docs.google.com/document/d/1oMswDB1Cbzjkxh-FUdxGapPHUi0IV1YRqXeDSGt5ZWk/edit?tab=t.0#heading=h.4nr3f9pj4xli for metrics DROP DOWN/check all that apply\n",
    "* look into metrics at the same time as generation\n",
    "* clear cache between iterations\n",
    "* store token/cost estimate\n",
    "* compare cossign similarity score between each step between iteration then average, and std\n",
    "* after eval is done return to stats to user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for row in range(df.shape[0]):\n",
    "    for col in range(2, df.shape[1]):\n",
    "        label = responses[0]['user']['steps'][df.columns[col]]\n",
    "        prompt = (\n",
    "            f\"Given information about the following {str.upper(df.iloc[row, col-1])}\"\n",
    "            f\"Step {str.upper(df.columns[col])}: {label} Please respond with ONLY the {df.columns[col]} step and absolutely no additional text or explanation.\"\n",
    "        )\n",
    "        genai.configure(api_key=key)\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        response = model.generate_content(prompt,\n",
    "                                          generation_config=genai.types.GenerationConfig(\n",
    "                                              temperature=1.0))\n",
    "        df.iloc[row, col] = response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df.to_csv('sample.csv', index=False)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# load embeddings\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Set the model in evaluation mode to deactivate the DropOut modules to have reproducible results during evaluation\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, random_mask_option=False, indexed_tokens=True):\n",
    "    # Basic text normalization (optional)\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = re.sub(' +', ' ', text)  # Remove extra spaces\n",
    "    text = text.strip()\n",
    "\n",
    "    # Tokenize input\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "\n",
    "    '''Masking Option: To mask a token that we will try to predict back\n",
    "    Masking a token can help improve the model's robustness and ability to generalize. \n",
    "    If the goal is to train or fine-tune a BERT model on a specific dataset using the MLM objective, we need to mask tokens during preprocessing. \n",
    "    This trains the model to better understand the context and improve its ability to predict or understand missing words.\n",
    "    This helps the model to learn bidirectional context representations. \n",
    "    By predicting the masked tokens, BERT learns to understand the context of a word from both its left and right surroundings. \n",
    "    In here this is left optional because For tasks where we just want to extract embeddings for text \n",
    "    (e.g., for text similarity, clustering), masking is not necessary.'''\n",
    "    if random_mask_option:\n",
    "        mask_index = random.randint(\n",
    "            1, len(tokenized_text) - 2) if len(tokenized_text) > 2 else 0\n",
    "        if len(tokenized_text) > 0:\n",
    "            tokenized_text[mask_index] = '[MASK]'\n",
    "\n",
    "    '''Convert tokens to vocabulary indices\n",
    "    BERT models and other transformer-based models require numerical input. \n",
    "    Specifically, they need token IDs that map to the model's vocabulary.'''\n",
    "    if indexed_tokens:\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        return indexed_tokens\n",
    "    else:\n",
    "        return tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embeddings(indexed_tokens):\n",
    "    # Convert indexed tokens to tensor and create attention mask\n",
    "    input_ids = torch.tensor([indexed_tokens])\n",
    "    attention_mask = torch.tensor([[1] * len(indexed_tokens)])\n",
    "\n",
    "    # Get the embeddings from BERT\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "    # The embeddings of the `[CLS]` token (representing the whole sentence) can be used\n",
    "    sentence_embedding = last_hidden_states[:, 0, :].squeeze()\n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the cosine similarity between two vectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calculate_cosine_similarity(embedding1, embedding2):\n",
    "    embedding1 = embedding1.unsqueeze(0)  # Add batch dimension\n",
    "    embedding2 = embedding2.unsqueeze(0)  # Add batch dimension\n",
    "    similarity = cosine_similarity(embedding1, embedding2)\n",
    "    return similarity[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>problem or task representation</th>\n",
       "      <th>preparation</th>\n",
       "      <th>generation</th>\n",
       "      <th>validation</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Over the past several years, advanced footwear...</td>\n",
       "      <td>Over the past several years, advanced footwear...</td>\n",
       "      <td>**Problem:** Heat buildup inside running shoes...</td>\n",
       "      <td>Develop a breathable, moisture-wicking shoe up...</td>\n",
       "      <td>Validate breathability and moisture-wicking pe...</td>\n",
       "      <td>Assess if the test has been passed perfectly—i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Over the past several years, advanced footwear...</td>\n",
       "      <td>Over the past several years, advanced footwear...</td>\n",
       "      <td>* **Heat transfer in materials:** Understandin...</td>\n",
       "      <td>Develop a running shoe incorporating PCMs in t...</td>\n",
       "      <td>Validation would involve comparing CFD simulat...</td>\n",
       "      <td>Assess if the test has been passed perfectly—i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Over the past several years, advanced footwear...</td>\n",
       "      <td>Over the past several years, advanced footwear...</td>\n",
       "      <td>* **Problem:** Heat buildup inside running sho...</td>\n",
       "      <td>Improved ventilation through laser-perforated ...</td>\n",
       "      <td>Validation requires empirical testing of each ...</td>\n",
       "      <td>Step OUTCOME: assess if the test has been pass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Over the past several years, advanced footwear...</td>\n",
       "      <td>Over the past several years, advanced footwear...</td>\n",
       "      <td>**Problem:** Heat buildup inside running shoes...</td>\n",
       "      <td>Develop prototypes using various mesh densitie...</td>\n",
       "      <td>Compare CFD simulation results with experiment...</td>\n",
       "      <td>Step OUTCOME:\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Over the past several years, advanced footwear...</td>\n",
       "      <td>Over the past several years, advanced footwear...</td>\n",
       "      <td>* **Heat dissipation in materials science:** R...</td>\n",
       "      <td>Develop a novel running shoe incorporating por...</td>\n",
       "      <td>Validate the design and manufacturing process ...</td>\n",
       "      <td>Step OUTCOME:\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                seed  \\\n",
       "0  Over the past several years, advanced footwear...   \n",
       "1  Over the past several years, advanced footwear...   \n",
       "2  Over the past several years, advanced footwear...   \n",
       "3  Over the past several years, advanced footwear...   \n",
       "4  Over the past several years, advanced footwear...   \n",
       "\n",
       "                      problem or task representation  \\\n",
       "0  Over the past several years, advanced footwear...   \n",
       "1  Over the past several years, advanced footwear...   \n",
       "2  Over the past several years, advanced footwear...   \n",
       "3  Over the past several years, advanced footwear...   \n",
       "4  Over the past several years, advanced footwear...   \n",
       "\n",
       "                                         preparation  \\\n",
       "0  **Problem:** Heat buildup inside running shoes...   \n",
       "1  * **Heat transfer in materials:** Understandin...   \n",
       "2  * **Problem:** Heat buildup inside running sho...   \n",
       "3  **Problem:** Heat buildup inside running shoes...   \n",
       "4  * **Heat dissipation in materials science:** R...   \n",
       "\n",
       "                                          generation  \\\n",
       "0  Develop a breathable, moisture-wicking shoe up...   \n",
       "1  Develop a running shoe incorporating PCMs in t...   \n",
       "2  Improved ventilation through laser-perforated ...   \n",
       "3  Develop prototypes using various mesh densitie...   \n",
       "4  Develop a novel running shoe incorporating por...   \n",
       "\n",
       "                                          validation  \\\n",
       "0  Validate breathability and moisture-wicking pe...   \n",
       "1  Validation would involve comparing CFD simulat...   \n",
       "2  Validation requires empirical testing of each ...   \n",
       "3  Compare CFD simulation results with experiment...   \n",
       "4  Validate the design and manufacturing process ...   \n",
       "\n",
       "                                             outcome  \n",
       "0  Assess if the test has been passed perfectly—i...  \n",
       "1  Assess if the test has been passed perfectly—i...  \n",
       "2  Step OUTCOME: assess if the test has been pass...  \n",
       "3                                    Step OUTCOME:\\n  \n",
       "4                                    Step OUTCOME:\\n  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'sample.csv'\n",
    "df = pd.read_csv(filepath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 1...\n",
      "Processing row 2...\n",
      "Processing row 3...\n",
      "Processing row 4...\n",
      "Processing row 5...\n",
      "Processing row 6...\n",
      "Processing row 7...\n",
      "Processing row 8...\n",
      "Processing row 9...\n",
      "Processing row 10...\n"
     ]
    }
   ],
   "source": [
    "# for every row in the df, preprocess the value of each column after the first one\n",
    "for i in range(len(df)):\n",
    "    print(f'Processing row {i+1}...')\n",
    "    steps = []\n",
    "    for j in range(1, len(df.columns)):\n",
    "        steps.append(get_bert_embeddings(preprocess_text(df.iloc[i, j])))\n",
    "\n",
    "    # for every pair of steps, compute the cosine similarity\n",
    "\n",
    "    # initializing a dataframe that is as long as the number of steps\n",
    "    df_similarities = pd.DataFrame(np.ones((len(steps), len(steps))), columns=range(\n",
    "        1, len(steps)+1), index=range(1, len(steps)+1))\n",
    "\n",
    "    for j in range(len(steps)):\n",
    "        for k in range(j+1, len(steps)):\n",
    "            df_similarities.iloc[j, k] = calculate_cosine_similarity(\n",
    "                steps[j], steps[k])\n",
    "\n",
    "    # make the bottom triangle of the matrix reflect the top triangle\n",
    "    for j in range(len(steps)):\n",
    "        for k in range(j+1, len(steps)):\n",
    "            df_similarities.iloc[k, j] = df_similarities.iloc[j, k]\n",
    "\n",
    "    df_similarities['Trial'] = i+1\n",
    "\n",
    "    # write df_similarities to a csv file\n",
    "    if i == 0:\n",
    "        df_similarities.to_csv(f'similarity_matrix.csv')\n",
    "    else:\n",
    "        df_similarities.to_csv(f'similarity_matrix.csv',\n",
    "                               mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Unnamed: 0    3.000000\n",
       " 1             0.691543\n",
       " 2             0.702099\n",
       " 3             0.683321\n",
       " 4             0.616077\n",
       " 5             0.607136\n",
       " Trial         5.500000\n",
       " dtype: float64,\n",
       " Unnamed: 0    1.428571\n",
       " 1             0.230359\n",
       " 2             0.219735\n",
       " 3             0.222898\n",
       " 4             0.226366\n",
       " 5             0.282082\n",
       " Trial         2.901442\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('similarity_matrix.csv')\n",
    "df1.mean(axis=0), df1.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.691543\n",
       "2    0.702099\n",
       "3    0.683321\n",
       "4    0.616077\n",
       "5    0.607136\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the similarity matrix data\n",
    "data = pd.read_csv(\"similarity_matrix.csv\")\n",
    "\n",
    "# Drop the Unnamed column if it exists (leftover from index saving)\n",
    "if \"Unnamed: 0\" in data.columns:\n",
    "    data = data.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "# Group rows by 'Trial' and compute the average similarity matrix\n",
    "average_matrix = data.groupby(\"Trial\").mean().mean(axis=0)\n",
    "average_matrix\n",
    "\n",
    "# # Convert to a clean DataFrame for display\n",
    "# average_df = pd.DataFrame(average_matrix)\n",
    "# average_df.columns = range(1, len(average_df) + 1)\n",
    "# average_df.index = range(1, len(average_df) + 1)\n",
    "\n",
    "# # Print the averaged similarity matrix\n",
    "# print(average_df)\n",
    "\n",
    "# # Optionally, save the average similarity matrix to a CSV\n",
    "# average_df.to_csv(\"average_similarity_matrix.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WORK IN PROGRESS: Evaluate each step of the process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses[0]\n",
    "\n",
    "crit_label = \"useful\"\n",
    "crit_def = 'degree to which something is valuable, helpful, or solves a problem.'\n",
    "\n",
    "\n",
    "for k, v in responses[0]['user']['steps'].items():\n",
    "\n",
    "    EVAL_STRING = prompt = (\n",
    "        f\"Based on the definition of '{crit_label}' — {crit_def} — \"\n",
    "        f\"rate the following {k} ({simulation[i][k]}) \"\n",
    "        f\"Use highly critical judgement and the entire range of this scale: \"\n",
    "        f\"1 (very low {crit_label}), \"\n",
    "        f\"2 (low {crit_label}), \"\n",
    "        f\"3 (slightly low {crit_label}), \"\n",
    "        f\"4 (moderate {crit_label}), \"\n",
    "        f\"5 (slightly high {crit_label}), \"\n",
    "        f\"6 (high {crit_label}), \"\n",
    "        f\"7 (very high {crit_label}). \"\n",
    "        f\"Respond with ONLY a single number for an overall rating and absolutely no additional text or explanation.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sample.csv')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
